version: "3.8"

services:  
  app:
    image: ${CI_REGISTRY_IMAGE}/llm:${CI_LLM_IMAGE_TAG}
    restart: always
    command: python3 app.py --embeddings-hf-repo-id $EMBEDDINGS_HF_REPO_ID --llm-hf-repo-id $LLM_HF_REPO_ID --tensor-parallel-size $VLLM_TENSOR_PARALLEL_SIZE --gpu-memory-utilization $VLLM_GPU_MEMORY_UTILIZATION $FORCE_DOWNLOAD $DEBUG --models-dir /models --host 0.0.0.0 --port 8000
    environment:
      - HF_TOKEN=${HF_TOKEN}
    ports:
      - ${LLM_PORT:-8000}:8000
    volumes:
      - ${MODELS_CACHE_DIR:-"/data/models"}:/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 120s
      timeout: 5s
      retries: 10

