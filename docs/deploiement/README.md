# DÃ©ploiement

Le projet Albert est composÃ© de plusieurs services Ã  dÃ©ployer :
- pyalbert
- llm
- api
- embeddings

Pour cela vous devez d'abord disposer d'un environment rÃ©pondant aux exigences requises ([Requirements](#requirements)). Puis deux installation sont possibles : sans Docker ([Installation locale (sans Docker)](#installation-locale-sans-docker)) ou avec ([DÃ©ploiement en CI/CD (avec Docker)](#dÃ©ploiement-en-cicd-avec-docker)).

**Tables des matiÃ¨res**

[[_TOC_]]

## Requirements

Le projet est concÃ§u pour fonctionner sur l'environnement Linux Ubuntu 22.04 LTS. De plus, les packages sont nÃ©cessaires :

* jq
* python3.10
* python3.10-venv
* nvidia-driver-535
* nvidia-cuda-toolkit
* nvidia-cuda-toolkit-gcc

*Pour docker :*
* nvidia-container-toolkit
* docker-ce
* docker-ce-cli
* containerd.io
* docker-buildx-plugin
* docker-compose-plugin

Pour un dÃ©ploiement en production vous pouvez utiliser le script [init_vm.sh](../../utils/init_vm.sh) pour configurer l'environnement nÃ©cessaire au projet Albert. Copiez le script sur le serveur et exÃ©cutez la commande suivante :

```bash
bash ./init_vm.sh
```

Ce script permet d'installer les packages nÃ©cessaires ainsi que de crÃ©er un utilisateur *gitlab* qui sera nÃ©cessaire pour le dÃ©ploiement de la pipeline de CI/CD. Pour exÃ©cuter le script il est nÃ©cessaire d'exporter prÃ©alablement les variables suivantes :
* `GITLAB_PASSWORD` (mot de passe de l'utilisateur *gitlab*)
* `GITLAB_SSH_PUBLIC_KEY` (clef public qui sera ajoutÃ© Ã  l'utilisateur *gitlab*)

## Installation locale (sans Docker)

* Clonez le repository

	```bash
	git clone git@gitlab.com:etalab-datalab/llm/albert-backend.git ~/albert-backend && cd ~/albert-backend
	```

* CrÃ©ez un environnement virtuel python et l'activer

	```bash
	mkdir ~/albert && python3 -m venv ~/albert && source ~/albert/bin/activate
	```

	> âš ï¸ Vous devez crÃ©er cet environment avec Python 3.10.

### Pyalbert 

* Installez les packages nÃ©cessaires

	```bash
	pip install -r ./pyalbert/requirements.txt
	```

* Ajoutez pyalbert aux librairies de votre environment virtuel

	```bash
	ln -s ./pyalbert albert/lib/python3.10/site-packages
	```

	> âš ï¸ Remplacez la version de Python par celle correspondante Ã  votre environment si celle-ci n'est pas 3.10.

### LLM


* Installez les packages nÃ©cessaires

	```bash
	pip install -r ./llm/vllm/requirements.txt
	pip install -r ./llm/gpt4all/requirements.txt
	```

* Lancer un modÃ¨le

	Le script [launch_local_llm.sh](../../utils/launch_local_llm.sh) permet de tÃ©lÃ©charger et lancer l'API d'un modÃ¨le Albert en une seule ligne de commande. Vous pouvez dÃ©ployer un modÃ¨le avec deux drivers : vllm ou gpt4all. Pour plus d'information, rendez vous sur la documentation [models.md](../models.md) qui dÃ©taille la configuration des diffÃ©rents modÃ¨les Albert disponibles.
 
	```bash
	bash ./utils/launch_local_llm.sh \
	-s STORAGE_PATH \
	-r HF_REPO_ID \
	-p PORT \
	-d DRIVER
	```

	Par exemple pour lancer [tiny-albert](https://huggingface.co/AgentPublic/tiny-albert) :

	```bash
	bash ./utils/launch_local_llm.sh -s ~/models -r AgentPublic/tiny-albert -d gpt4all -p 8000 -m ggml-model-expert-q4_K.bin
	```

	Ou encore pour lancer [albert-light](https://huggingface.co/AgentPublic/albert-light) :

	```bash
	bash ./utils/launch_local_llm.sh -s ~/models -r AgentPublic/albert-light -d vllm -p 8000
	```

### Reverse proxy (Nginx)

* Installez Nginx

	```bash
	sudo apt install nginx
	```

* Configurez Nginx pour rediriger les requÃªtes vers l'API, activez le vhost et redÃ©marrez Nginx:

	```bash
	sudo cp ./contrib/nginx/albert.conf /etc/nginx/sites-available/albert.conf
	sudo ln -s /etc/nginx/sites-available/albert /etc/nginx/sites-enabled
	sudo systemctl restart nginx
	```

* Installez certbot

	```bash
	sudo apt install certbot python3-certbot-nginx
	```

* CrÃ©ez un certificat SSL pour votre domaine

	```bash
	sudo certbot --nginx -d mondomaine.com
	```

	Vous pouvez ensuite vÃ©rifier que le certificat a Ã©tÃ© correctement installÃ© en regardant si le fichier `/etc/nginx/sites-available/albert.conf` a bien Ã©tÃ© modifiÃ©:
	```bash
	cat /etc/nginx/sites-available/albert.conf
	```

* Optionnel : installez et configurez le firewall pour Nginx

	```bash
	sudo apt install ufw
	sudo ufw allow 'Nginx Full'
	sudo ufw allow ssh # trÃ¨s important! pour conserver sa connection ssh
	sudo ufw enable
	```

* Optionnel : n'oubliez pas d'installer et d'activer fail2ban

	```bash
	sudo apt install fail2ban
	sudo systemctl start fail2ban # pour le dÃ©marrer
	sudo systemctl enable fail2ban # pour le dÃ©marrer au dÃ©marrage
	```

### Databases

* CrÃ©er un fichier de variable d'environnement avec les variables suivantes :

	* `POSTGRES_PASSWORD`
    * `POSTGRES_PORT`
    * `ELASTIC_PASSWORD`
  	* `ELASTIC_PORT`
    * `QDRANT_REST_PORT`
	* `QDRANT_GRPC_PORT`
    * `COMPOSE_FILE`
    * `COMPOSE_PROJECT_NAME`

	Pour plus d'informations sur la valeur des variables voir la documentation dÃ©diÃ©es [environments.md](environments.md).

	Les variables `COMPOSE_FILE` et `COMPOSE_PROJECT_NAME` sont des variables prÃ©dÃ©finies par Docker, pour plus d'information voir la [documentation officielle]( https://docs.docker.com/compose/environment-variables/envvars/).


* DÃ©ployer les bases de donnÃ©es

	```bash
	docker compose --env-file=PATH_TO_ENV_FILE down && docker compose --env-file=PATH_TO_ENV_FILE up --detach
	```

### RAG

> Par dÃ©faut les fichiers tÃ©lÃ©chargÃ©s et gÃ©nÃ©rÃ©s dans cette section seront mis dans un dossier *./_data*.

* Pour activer la fonctionnalitÃ© de RAG, vous devez tout d'abord tÃ©lÃ©chargez les documents qui vont alimenter le systÃ¨me : 

	```bash
    python3 ./pyalbert.py download_corpus
	```

* Vous devez ensuite appliquer un preprocessing sur ces documents : 

	```bash
    python3 ./pyalbert.py make_chunks --structured
	```

* Puis, vous devez crÃ©er des vecteurs Ã  l'aide d'un modÃ¨le d'embeddings 

	```bash
    python3 ./pyalbert.py make_embeddings
	```

* Enfin vous devez intÃ©grer les documents et ces vectors dans les bases de donnÃ©es dÃ©diÃ©s qui ont Ã©tÃ© dÃ©ployÃ©es dans la section prÃ©cÃ©dente

	```bash
    # Elasticsearch indexes
    python3 ./pyalbert.py index experiences --index-type bm25
    python3 ./pyalbert.py index sheets --index-type bm25
    python3 ./pyalbert.py index chunks --index-type bm25

    # Qdrant indexes (aka collections)
    python3 ./pyalbert.py index experiences --index-type e5
    python3 ./pyalbert.py index chunks --index-type e5
	```

### API

#### Avec docker

* Exportez les variables d'environnement suivantes :

	* `API_PORT`
	* `LLM_TABLE`
	* `API_URL`
	* `FRONT_URL`
	* `POSTGRES_PASSWORD`
    * `POSTGRES_PORT`
    * `POSTGRES_HOST`

	Exportez Ã©galement les variables suivantes pour spÃ©cifier oÃ¹ trouver les bases de donnÃ©es nÃ©cessaires au RAG : 

	* `ELASTIC_HOST`
  	* `ELASTIC_PORT`
	* `ELASTIC_PASSWORD`
	* `QDRANT_HOST`
    * `QDRANT_REST_PORT`
	* `QDRANT_GRPC_PORT`

* DÃ©ployÃ© un container d'API : 
	
	```bash
    docker run --gpus all -it --publish ${API_PORT}:8090 --restart always --name albert-api-v2 \
    --env POSTGRES_HOST=${POSTGRES_HOST} \
    --env POSTGRES_PORT=${POSTGRES_PORT} \
    --env POSTGRES_PASSWORD=${POSTGRES_PASSWORD} \
    --env QDRANT_HOST=${QDRANT_HOST} \
    --env QDRANT_REST_PORT=${QDRANT_REST_PORT} \
    --env QDRANT_GRPC_PORT=${QDRANT_GRPC_PORT} \
    --env ELASTIC_HOST=${ELASTIC_HOST} \
    --env ELASTIC_PORT=${ELASTIC_PORT} \
    --env API_URL=${CI_DEPLOY_URL} \
    --env FRONT_URL=${CI_DEPLOY_URL} \
    --env "LLM_TABLE=${LLM_TABLE}" \
    ${CI_REGISTRY_IMAGE}/api:${CI_API_IMAGE_TAG}
	```

## Installation avec Docker

L'installation avec Docker se fait dans le cadre d'un pipeline de CI/CD Gitlab. RefÃ©rez-vous au fichier [.gitlab-ci.yml](../../.gitlab-ci.yml) pour plus d'information sur les Ã©tapes de dÃ©ploiement rÃ©alisÃ©e. Afin d'exÃ©cuter cette pipeline il est nÃ©cessaire de configurer au prÃ©alable certaines variables d'environnement dans Gitlab. Pour cela rendez vous sur la documentation [environments.md](environments.md).

Les Ã©tapes de CI/CD (dupliquÃ©es pour chaque environnement) sont dÃ©crites schÃ©matiquement ici :

```mermaid
---
title: "Albert deployment flow"
---
graph TD

subgraph VLLM["VLLM"]
    job_vllm_build["build"]
    -.-> job_vllm_setup["setup\n[pyalbert/albert.py]\ndownload_models"]
    -.-> job_vllm_deploy["deploy\n(manual)"]
    -.-> job_vllm_test["test"]
end

subgraph API["API"]
    job_api_build["build"]
    -.-> job_api_setup["setup\n[pyalbert/albert.py]\ncreate_whitelist"]
    -.-> job_api_deploy["deploy\n(manual)"]
    -.-> job_api_test["test"]

end

job_pre["link gpu"]
job_post["unlink gpu"]

job_pre -.-> |"only staging"| VLLM
job_pre -.-> |"only staging"| API
VLLM -.-> |"only staging"| job_post
API -.-> |"only staging"| job_post
```

* Configurez les modÃ¨les Ã  dÃ©ployer dans le fichier [llm_routing_table.json](../../pyalbert/config/llm_routing_table.json)

	Pour plus d'information sur comment configurer ce fichier, rendez vous sur la documentation [models.md](../models.md) qui dÃ©taille la configuration des diffÃ©rents modÃ¨les disponibles.

* TÃ©lÃ©chargez les modÃ¨les spÃ©cifiez dans le fichier de configuration

	```bash
	python albert-backend/pyalbert/albert.py download_model --storage-dir=STORAGE_PATH --hf-repo-id=
	```

	> ğŸ’¡ Remplacez STORAGE_PATH par l'emplacement oÃ¹ vous souhaitez stocker les modÃ¨les et ENV par la valeur que vous avez mentionnÃ©e dans le fichier de configuration.
