{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c5dc9-648e-4a51-9974-c5e5525a29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "albert_url = \"https://albert.etalab.gouv.fr/api/v1\"\n",
    "albert_api_key = \"YOUR_ALBERT_API_TOKEN\"\n",
    "\n",
    "# Pick a model\n",
    "albert_model = \"AgentPublic/llama3-instruct-8b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa930c76-a885-44d8-b9e7-88d5d04d902f",
   "metadata": {},
   "source": [
    "# Use Albert with user-defined conversation (no RAG on the albert side)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c430885-ba7b-41ea-bbe1-c883460ee26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Albert with user-defined conversation (no RAG on the albert side)\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=albert_url,\n",
    "    api_key=albert_api_key,\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=albert_model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "    ],\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "answer = completion.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed909d82-c1f4-4984-aa08-83a7d9690b53",
   "metadata": {},
   "source": [
    "# Use Albert with user-defined conversation with the RAG feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3721a14-b487-464b-affd-be7eadaac060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Albert with user-defined conversation with the RAG feature.\n",
    "\n",
    "conversation = {\n",
    "    \"model\": albert_model,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Tu réponds aux questions en t'appuyant si possible sur les sources données. Cite les références pertinentes en fin de réponse.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Quelle est la procédure pour contacter la Direction Générale de la Concurrence, de la Consommation et de la Répression des Fraudes (DGCCRF) en cas de litige avec une entreprise ou un magasin ?\",\n",
    "        },\n",
    "    ],\n",
    "    # Only \"last\" is supported as of today. It will \"augment\" the last user query\n",
    "    # with pertinent sources and predefined template prompt. You can change the\n",
    "    # template prompt used with parameter \"mode\". Note that if you use a system prompt it will overwrite any predefined one the template. see [[doc]]\n",
    "    \"rag\": \"last\",\n",
    "    \"limit\": 7,  # How many sources will be included in the prompt.\n",
    "}\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {albert_api_key}\"}\n",
    "response = requests.post(f\"{albert_url}/chat/completions\", headers=headers, json=conversation)\n",
    "answer = response.json()[\"choices\"][0][\"message\"]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5840363-b4d7-42bd-9bfa-c11f8ce0558a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
